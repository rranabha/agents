{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T13:51:44.797696Z",
     "iopub.status.busy": "2026-02-02T13:51:44.797478Z",
     "iopub.status.idle": "2026-02-02T13:52:44.507335Z",
     "shell.execute_reply": "2026-02-02T13:52:44.505751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: What were the top 3 headlines about NVIDIA in the last 7 days? Include sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:8321/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: resp_ab3e44ed-5626-45dd-813f-2e99cb028713\n",
      "Response status: completed\n",
      "  - Type: web_search_call, Status: completed\n",
      "  - Type: web_search_call, Status: completed\n",
      "  - Type: web_search_call, Status: completed\n",
      "  - Type: web_search_call, Status: completed\n",
      "  - Type: web_search_call, Status: completed\n",
      "  - Type: message, Status: completed\n",
      "\n",
      "Diagnostics:\n",
      "  Search triggered: True\n",
      "  Tool calls: 5\n",
      "  Messages: 1\n",
      "  Total iterations: 6\n",
      "\n",
      "============================================================\n",
      "Response from GPT-OSS-20b with vLLM 0.11.2+rhai5 (2026-02-02)\n",
      "============================================================\n",
      "(empty response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: What is the latest stable release of vLLM and its release date? Cite sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:8321/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: resp_dbf3f093-bd33-47c8-8b2e-0d4c00744204\n",
      "Response status: completed\n",
      "  - Type: web_search_call, Status: completed\n",
      "  - Type: web_search_call, Status: failed\n",
      "  - Type: web_search_call, Status: failed\n",
      "  - Type: message, Status: completed\n",
      "\n",
      "Diagnostics:\n",
      "  Search triggered: True\n",
      "  Tool calls: 3\n",
      "  Messages: 1\n",
      "  Total iterations: 4\n",
      "\n",
      "============================================================\n",
      "Response from GPT-OSS-20b with vLLM 0.11.2+rhai5 (2026-02-02)\n",
      "============================================================\n",
      "(empty response)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: What is the most recent U.S. CPI (inflation) release and its month-over-month value? Cite sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:8321/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID: resp_481eb5c7-84e0-4f36-8115-f035e59dd2cc\n",
      "Response status: completed\n",
      "  - Type: web_search_call, Status: completed\n",
      "  - Type: message, Status: completed\n",
      "\n",
      "Diagnostics:\n",
      "  Search triggered: True\n",
      "  Tool calls: 1\n",
      "  Messages: 1\n",
      "  Total iterations: 2\n",
      "\n",
      "============================================================\n",
      "Response from GPT-OSS-20b with vLLM 0.11.2+rhai5 (2026-02-02)\n",
      "============================================================\n",
      "(empty response)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import date\n",
    "from dotenv import load_dotenv\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from time import sleep\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LLAMA_STACK_URL = os.getenv(\"LLAMA_STACK_URL\", \"http://127.0.0.1:8321\")\n",
    "MODEL_ID = \"vllm/openai/gpt-oss-20b\"\n",
    "MODEL_LABEL = \"GPT-OSS-20b\"\n",
    "VLLM_VERSION = \"0.11.2+rhai5\"\n",
    "RUN_DATE = os.getenv(\"RUN_DATE\", date.today().isoformat())\n",
    "\n",
    "MAX_TOOL_CALLS = 20\n",
    "MAX_INFER_ITERS = 20\n",
    "\n",
    "# Use llama-stack client (supports max_infer_iters parameter, unlike OpenAI client)\n",
    "client = LlamaStackClient(base_url=LLAMA_STACK_URL)\n",
    "\n",
    "# Note: Using llama-stack client to pass max_infer_iters directly (not supported by OpenAI client).\n",
    "# max_infer_iters controls the total number of iterations (tool calls + final message).\n",
    "# max_tool_calls limits the number of tool calls within those iterations.\n",
    "\n",
    "PROMPTS = [\n",
    "    \"What were the top 3 headlines about NVIDIA in the last 7 days? Include sources.\",\n",
    "    \"What is the latest stable release of vLLM and its release date? Cite sources.\",\n",
    "    \"What is the most recent U.S. CPI (inflation) release and its month-over-month value? Cite sources.\"\n",
    "]\n",
    "\n",
    "\n",
    "def normalize_result(result):\n",
    "    if isinstance(result, dict):\n",
    "        return result\n",
    "    if hasattr(result, \"model_dump\"):\n",
    "        return result.model_dump()\n",
    "    if hasattr(result, \"__dict__\"):\n",
    "        return result.__dict__\n",
    "    return {\"value\": str(result)}\n",
    "\n",
    "\n",
    "def print_search_results(item):\n",
    "    results = getattr(item, \"results\", None)\n",
    "    if results is None:\n",
    "        return\n",
    "    print(\"    Results:\")\n",
    "    for idx, result in enumerate(results, 1):\n",
    "        data = normalize_result(result)\n",
    "        title = data.get(\"title\")\n",
    "        url = data.get(\"url\")\n",
    "        snippet = data.get(\"snippet\") or data.get(\"content\")\n",
    "        print(f\"      {idx}. {title}\")\n",
    "        if url:\n",
    "            print(f\"         URL: {url}\")\n",
    "        if snippet:\n",
    "            print(f\"         Snippet: {snippet}\")\n",
    "\n",
    "\n",
    "def run_prompt(prompt):\n",
    "    print(f\"\\nUser: {prompt}\")\n",
    "    response = client.responses.create(\n",
    "        model=MODEL_ID,\n",
    "        tools=[{\"type\": \"web_search\"}],\n",
    "        input=prompt,\n",
    "        max_tool_calls=MAX_TOOL_CALLS,\n",
    "        max_infer_iters=MAX_INFER_ITERS\n",
    "    )\n",
    "\n",
    "    print(f\"Response ID: {response.id}\")\n",
    "    print(f\"Response status: {response.status}\")\n",
    "    \n",
    "    search_triggered = False\n",
    "    tool_call_count = 0\n",
    "    message_count = 0\n",
    "\n",
    "    for item in response.output:\n",
    "        item_type = getattr(item, \"type\", \"unknown\")\n",
    "        item_status = getattr(item, \"status\", \"unknown\")\n",
    "        print(f\"  - Type: {item_type}, Status: {item_status}\")\n",
    "        if \"search\" in item_type:\n",
    "            search_triggered = True\n",
    "            tool_call_count += 1\n",
    "        elif item_type == \"message\":\n",
    "            message_count += 1\n",
    "        query = getattr(item, \"query\", None)\n",
    "        if query:\n",
    "            print(f\"    Query: {query}\")\n",
    "        print_search_results(item)\n",
    "\n",
    "    print(\"\\nDiagnostics:\")\n",
    "    print(f\"  Search triggered: {search_triggered}\")\n",
    "    print(f\"  Tool calls: {tool_call_count}\")\n",
    "    print(f\"  Messages: {message_count}\")\n",
    "    \n",
    "    print(f\"  Total iterations: {tool_call_count + message_count}\")\n",
    "    \n",
    "    # Check for max_infer_iters issue\n",
    "    if response.status == \"incomplete\" and tool_call_count >= MAX_TOOL_CALLS and message_count == 0:\n",
    "        print(f\"  ⚠️  WARNING: Likely hit max_tool_calls limit ({MAX_TOOL_CALLS})\")\n",
    "        print(f\"     Model used {tool_call_count} tool calls, leaving no iterations for final message\")\n",
    "    elif response.status == \"incomplete\" and (tool_call_count + message_count) >= MAX_INFER_ITERS:\n",
    "        print(f\"  ⚠️  WARNING: Likely hit max_infer_iters limit ({MAX_INFER_ITERS})\")\n",
    "        print(f\"     Total iterations: {tool_call_count + message_count}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Response from {MODEL_LABEL} with vLLM {VLLM_VERSION} ({RUN_DATE})\")\n",
    "    print(\"=\" * 60)\n",
    "    if response.output_text:\n",
    "        print(response.output_text)\n",
    "    else:\n",
    "        print(\"(empty response)\")\n",
    "    return response\n",
    "\n",
    "\n",
    "try:\n",
    "    for prompt in PROMPTS:\n",
    "        run_prompt(prompt)\n",
    "        sleep(10)  # Brief pause between prompts\n",
    "finally:\n",
    "    # llama-stack client doesn't need explicit close, but keeping for consistency\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Output (2026-01-31)\n",
    "\n",
    "## Prompt 1\n",
    "\n",
    "**Timestamp:** 2026-01-31 14:57:07\n",
    "\n",
    "**Prompt:** What were the top 3 headlines about NVIDIA in the last 7 days? Include sources.\n",
    "\n",
    "**Search triggered:** True\n",
    "\n",
    "**Search calls completed:** 4\n",
    "\n",
    "**Search calls failed:** 0\n",
    "\n",
    "**Response status:** completed\n",
    "\n",
    "**Tool calls:** 4\n",
    "\n",
    "**Messages:** 1\n",
    "\n",
    "**Response ID:** resp_b528f809-e273-4e9d-9b6d-2d9b3b9a794e\n",
    "\n",
    "**Response text:**\n",
    "\n",
    "**Top 3 NVIDIA headlines (Jan 24‑31 2026)**  \n",
    "\n",
    "| Date | Headline | Source |\n",
    "|------|----------|--------|\n",
    "| **January 31 2026** | “Nvidia CEO Huang denies he is unhappy with OpenAI, says ‘huge’ investment planned” | Reuters – [link](https://www.reuters.com/world/asia-pacific/nvidia-ceo-huang-denies-he-is-unhappy-with-openai-says-huge-investment-planned-2026-01-31/) |\n",
    "| **January 31 2026** | “Nvidia’s plan to invest up to $100 billion in OpenAI has stalled, WSJ reports” | Reuters – [link](https://www.reuters.com/business/nvidias-plan-invest-up-100-billion-openai-has-stalled-wsj-reports-2026-01-31/) |\n",
    "| **January 28 2026** | “Exclusive: China gives nod to ByteDance, Alibaba and Tencent to buy Nvidia’s H200 chips – sources” | Reuters – [link](https://www.reuters.com/world/china/china-gives-green-light-importing-first-batch-nvidias-h200-ai-chips-sources-say-2026-01-28/) |\n",
    "\n",
    "These three stories were among the most widely cited and discussed in the news cycle during the past week, covering Nvidia’s strategic partnership talks with OpenAI, the status of the planned $100 billion investment, and a key regulatory milestone in China granting import permission for Nvidia’s H200 AI chips.\n",
    "\n",
    "---\n",
    "\n",
    "## Prompt 2\n",
    "\n",
    "**Timestamp:** 2026-01-31 14:57:07\n",
    "\n",
    "**Prompt:** What is the latest stable release of vLLM and its release date? Cite sources.\n",
    "\n",
    "**Search triggered:** True\n",
    "\n",
    "**Search calls completed:** 2\n",
    "\n",
    "**Search calls failed:** 1\n",
    "\n",
    "**Response status:** completed\n",
    "\n",
    "**Tool calls:** 3\n",
    "\n",
    "**Messages:** 1\n",
    "\n",
    "**Response ID:** resp_05d63d0b-e892-4a7c-93a9-07d4d573b936\n",
    "\n",
    "**Response text:**\n",
    "\n",
    "(empty response)\n",
    "\n",
    "---\n",
    "\n",
    "## Prompt 3\n",
    "\n",
    "**Timestamp:** 2026-01-31 14:57:07\n",
    "\n",
    "**Prompt:** What is the most recent U.S. CPI (inflation) release and its month-over-month value? Cite sources.\n",
    "\n",
    "**Search triggered:** True\n",
    "\n",
    "**Search calls completed:** 5\n",
    "\n",
    "**Search calls failed:** 2\n",
    "\n",
    "**Response status:** completed\n",
    "\n",
    "**Tool calls:** 7\n",
    "\n",
    "**Messages:** 1\n",
    "\n",
    "**Response ID:** resp_5f876832-eda3-4c61-8b93-650bc6253041\n",
    "\n",
    "**Response text:**\n",
    "\n",
    "(empty response)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Response JSON (with metadata)\n",
    "\n",
    "### Prompt 1\n",
    "\n",
    "**Timestamp:** 2026-01-31 14:57:07\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"resp_b528f809-e273-4e9d-9b6d-2d9b3b9a794e\",\n",
    "  \"created_at\": 1769889298,\n",
    "  \"model\": \"vllm/openai/gpt-oss-20b\",\n",
    "  \"output\": [\n",
    "    {\n",
    "      \"id\": \"fc_ceb3fa27-2249-4ef7-9f27-f835ec5a6f30\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_23193bdd-ddcf-43f6-b187-8c389e7dca6d\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_45bf2237-2245-4b5a-bf2d-5288a34b6d1d\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_7201029b-f2d8-4b45-8f0d-21d60a72ead2\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"**Top 3 NVIDIA headlines (Jan\\u202f24\\u201131\\u202f2026)**  \\n\\n| Date | Headline | Source |\\n|------|----------|--------|\\n| **January\\u202f31\\u202f2026** | \\u201cNvidia CEO Huang denies he is unhappy with OpenAI, says \\u2018huge\\u2019 investment planned\\u201d | Reuters \\u2013 [link](https://www.reuters.com/world/asia-pacific/nvidia-ceo-huang-denies-he-is-unhappy-with-openai-says-huge-investment-planned-2026-01-31/) |\\n| **January\\u202f31\\u202f2026** | \\u201cNvidia\\u2019s plan to invest up to $100\\u202fbillion in OpenAI has stalled, WSJ reports\\u201d | Reuters \\u2013 [link](https://www.reuters.com/business/nvidias-plan-invest-up-100-billion-openai-has-stalled-wsj-reports-2026-01-31/) |\\n| **January\\u202f28\\u202f2026** | \\u201cExclusive: China gives nod to ByteDance, Alibaba and Tencent to buy Nvidia\\u2019s H200 chips \\u2013 sources\\u201d | Reuters \\u2013 [link](https://www.reuters.com/world/china/china-gives-green-light-importing-first-batch-nvidias-h200-ai-chips-sources-say-2026-01-28/) |\\n\\nThese three stories were among the most widely cited and discussed in the news cycle during the past week, covering Nvidia\\u2019s strategic partnership talks with OpenAI, the status of the planned $100\\u202fbillion investment, and a key regulatory milestone in China granting import permission for Nvidia\\u2019s H200 AI chips.\",\n",
    "          \"annotations\": [],\n",
    "          \"logprobs\": null,\n",
    "          \"type\": \"output_text\"\n",
    "        }\n",
    "      ],\n",
    "      \"role\": \"assistant\",\n",
    "      \"id\": \"msg_f35504cd-6b4f-499d-a10c-c439df7e505f\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"message\"\n",
    "    }\n",
    "  ],\n",
    "  \"status\": \"completed\",\n",
    "  \"error\": null,\n",
    "  \"instructions\": null,\n",
    "  \"max_tool_calls\": 20,\n",
    "  \"metadata\": null,\n",
    "  \"object\": \"response\",\n",
    "  \"parallel_tool_calls\": true,\n",
    "  \"previous_response_id\": null,\n",
    "  \"prompt\": null,\n",
    "  \"temperature\": null,\n",
    "  \"text\": {\n",
    "    \"format\": {\n",
    "      \"description\": null,\n",
    "      \"name\": null,\n",
    "      \"schema_\": null,\n",
    "      \"strict\": null,\n",
    "      \"type\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  \"tool_choice\": null,\n",
    "  \"tools\": {\n",
    "    \"value\": \"[ToolOpenAIResponseInputToolWebSearch(search_context_size='medium', type='web_search')]\"\n",
    "  },\n",
    "  \"top_p\": null,\n",
    "  \"truncation\": null,\n",
    "  \"usage\": {\n",
    "    \"input_tokens\": 8245,\n",
    "    \"output_tokens\": 1052,\n",
    "    \"total_tokens\": 9297,\n",
    "    \"input_tokens_details\": {\n",
    "      \"cached_tokens\": 0\n",
    "    },\n",
    "    \"output_tokens_details\": {\n",
    "      \"reasoning_tokens\": 0\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Prompt 2\n",
    "\n",
    "**Timestamp:** 2026-01-31 14:57:07\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"resp_05d63d0b-e892-4a7c-93a9-07d4d573b936\",\n",
    "  \"created_at\": 1769889332,\n",
    "  \"model\": \"vllm/openai/gpt-oss-20b\",\n",
    "  \"output\": [\n",
    "    {\n",
    "      \"id\": \"fc_c1169479-3903-4535-812b-fc09aec99dc8\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_66472e5c-5b82-417f-adac-16ef98dcef2b\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_300627c4-257e-42c9-96b0-4918b0aef0ad\",\n",
    "      \"status\": \"failed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"\",\n",
    "          \"annotations\": [],\n",
    "          \"logprobs\": null,\n",
    "          \"type\": \"output_text\"\n",
    "        }\n",
    "      ],\n",
    "      \"role\": \"assistant\",\n",
    "      \"id\": \"msg_f0701c28-8bd0-4b02-ac13-b67a657f65c4\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"message\"\n",
    "    }\n",
    "  ],\n",
    "  \"status\": \"completed\",\n",
    "  \"error\": null,\n",
    "  \"instructions\": null,\n",
    "  \"max_tool_calls\": 20,\n",
    "  \"metadata\": null,\n",
    "  \"object\": \"response\",\n",
    "  \"parallel_tool_calls\": true,\n",
    "  \"previous_response_id\": null,\n",
    "  \"prompt\": null,\n",
    "  \"temperature\": null,\n",
    "  \"text\": {\n",
    "    \"format\": {\n",
    "      \"description\": null,\n",
    "      \"name\": null,\n",
    "      \"schema_\": null,\n",
    "      \"strict\": null,\n",
    "      \"type\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  \"tool_choice\": null,\n",
    "  \"tools\": {\n",
    "    \"value\": \"[ToolOpenAIResponseInputToolWebSearch(search_context_size='medium', type='web_search')]\"\n",
    "  },\n",
    "  \"top_p\": null,\n",
    "  \"truncation\": null,\n",
    "  \"usage\": {\n",
    "    \"input_tokens\": 3004,\n",
    "    \"output_tokens\": 233,\n",
    "    \"total_tokens\": 3237,\n",
    "    \"input_tokens_details\": {\n",
    "      \"cached_tokens\": 0\n",
    "    },\n",
    "    \"output_tokens_details\": {\n",
    "      \"reasoning_tokens\": 0\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Prompt 3\n",
    "\n",
    "**Timestamp:** 2026-01-31 14:57:07\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"resp_5f876832-eda3-4c61-8b93-650bc6253041\",\n",
    "  \"created_at\": 1769889349,\n",
    "  \"model\": \"vllm/openai/gpt-oss-20b\",\n",
    "  \"output\": [\n",
    "    {\n",
    "      \"id\": \"fc_54db00d4-4a33-421c-a12a-01ba0529325b\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_8d07abdd-0322-46b5-85ea-a155cedc734d\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_128946d7-12ad-469f-b0dc-f4a0338b0d88\",\n",
    "      \"status\": \"failed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_9aff7a5c-d379-4f44-b825-182aeeb741e5\",\n",
    "      \"status\": \"failed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_63017ee9-a978-48fc-8913-fc283b145bf4\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_4bd43fd5-781d-423d-95fc-c631830e7546\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"fc_05289039-3bdb-4495-804b-858336c58e45\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"web_search_call\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"\",\n",
    "          \"annotations\": [],\n",
    "          \"logprobs\": null,\n",
    "          \"type\": \"output_text\"\n",
    "        }\n",
    "      ],\n",
    "      \"role\": \"assistant\",\n",
    "      \"id\": \"msg_24769db1-3dca-4955-a55f-04095a209bf8\",\n",
    "      \"status\": \"completed\",\n",
    "      \"type\": \"message\"\n",
    "    }\n",
    "  ],\n",
    "  \"status\": \"completed\",\n",
    "  \"error\": null,\n",
    "  \"instructions\": null,\n",
    "  \"max_tool_calls\": 20,\n",
    "  \"metadata\": null,\n",
    "  \"object\": \"response\",\n",
    "  \"parallel_tool_calls\": true,\n",
    "  \"previous_response_id\": null,\n",
    "  \"prompt\": null,\n",
    "  \"temperature\": null,\n",
    "  \"text\": {\n",
    "    \"format\": {\n",
    "      \"description\": null,\n",
    "      \"name\": null,\n",
    "      \"schema_\": null,\n",
    "      \"strict\": null,\n",
    "      \"type\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  \"tool_choice\": null,\n",
    "  \"tools\": {\n",
    "    \"value\": \"[ToolOpenAIResponseInputToolWebSearch(search_context_size='medium', type='web_search')]\"\n",
    "  },\n",
    "  \"top_p\": null,\n",
    "  \"truncation\": null,\n",
    "  \"usage\": {\n",
    "    \"input_tokens\": 9049,\n",
    "    \"output_tokens\": 1136,\n",
    "    \"total_tokens\": 10185,\n",
    "    \"input_tokens_details\": {\n",
    "      \"cached_tokens\": 0\n",
    "    },\n",
    "    \"output_tokens_details\": {\n",
    "      \"reasoning_tokens\": 0\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
