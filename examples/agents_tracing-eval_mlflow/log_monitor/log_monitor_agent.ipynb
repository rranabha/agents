{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "17069ebc",
      "metadata": {},
      "source": [
        "# Log Monitor Agent with MLflow Tracing & Evaluation\n",
        "\n",
        "An event-driven agent that monitors server logs using LangGraph.\n",
        "\n",
        "**Source:** The agent is from https://github.com/jwm4/agents/tree/001-log-monitor-agent/examples/log-monitor-agent\n",
        "\n",
        "**What we added:** MLflow tracing and Agent-as-a-Judge evaluation to demonstrate observability and automated evaluation of agent execution.\n",
        "\n",
        "**Prerequisites:**\n",
        "- Llama Stack server running at `http://localhost:8321`\n",
        "- `OPENAI_API_KEY` in environment (for Agent-as-a-Judge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a64ee0d2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/nnarendr/Documents/Repos/agents/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Add parent directory to path for imports\n",
        "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
        "\n",
        "# Load .env from parent directory (agents_tracing-eval_mlflow/.env)\n",
        "env_path = os.path.join(os.path.dirname(os.getcwd()), \".env\")\n",
        "load_dotenv(env_path)\n",
        "\n",
        "import mlflow\n",
        "from mlflow.entities import SpanType, AssessmentSource, AssessmentSourceType\n",
        "from mlflow.genai.judges import make_judge\n",
        "from typing import Literal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9989108",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "30b5168b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026/01/29 16:59:12 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.schemas\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.tables\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.types\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.constraints\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.defaults\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.plugins: setup plugin alembic.autogenerate.comments\n",
            "2026/01/29 16:59:12 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2026/01/29 16:59:12 INFO mlflow.store.db.utils: Updating database tables\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
            "2026/01/29 16:59:12 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
            "2026/01/29 16:59:13 INFO alembic.runtime.migration: Running upgrade 1bd49d398cd23 -> b7c8d9e0f1a2, add trace metrics table\n",
            "2026/01/29 16:59:13 INFO alembic.runtime.migration: Running upgrade b7c8d9e0f1a2 -> 5d2d30f0abce, update job table\n",
            "2026/01/29 16:59:13 INFO alembic.runtime.migration: Running upgrade 5d2d30f0abce -> c9d4e5f6a7b8, add routing strategy to endpoints and linkage type to mappings\n",
            "2026/01/29 16:59:13 INFO alembic.runtime.migration: Running upgrade c9d4e5f6a7b8 -> 2c33131f4dae, add online_scoring_configs table\n",
            "2026/01/29 16:59:13 INFO alembic.runtime.migration: Running upgrade 2c33131f4dae -> d3e4f5a6b7c8, add display_name to endpoint_bindings\n",
            "2026/01/29 16:59:13 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/01/29 16:59:13 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2026/01/29 16:59:13 INFO mlflow.tracking.fluent: Experiment with name 'log-monitor-agent' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow database: /Users/nnarendr/Documents/Repos/agents/agents_tracing-eval_mlflow/log_monitor/mlflow.db\n"
          ]
        }
      ],
      "source": [
        "# MLflow setup\n",
        "db_path = os.path.join(os.getcwd(), \"mlflow.db\")\n",
        "mlflow.set_tracking_uri(f\"sqlite:///{db_path}\")\n",
        "mlflow.set_experiment(\"log-monitor-agent\")\n",
        "print(f\"MLflow database: {db_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8eebc572",
      "metadata": {},
      "outputs": [],
      "source": [
        "JUDGE_MODEL = \"openai:/gpt-4o\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d816adc7",
      "metadata": {},
      "source": [
        "## Import the Agent\n",
        "\n",
        "The log monitor agent (from the source repo) implements a LangGraph workflow:\n",
        "1. **Classify** - error/warning/normal\n",
        "2. **Diagnose** - root cause analysis (uses MCP tools for documentation lookup)\n",
        "3. **Assess Severity** - high/low\n",
        "4. **Route** - Slack alert (high) or GitHub ticket (low)\n",
        "\n",
        "We added `@mlflow.trace` decorator and `mlflow.start_span` calls to capture execution traces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8b0cd38d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from log_monitor_agent.agent import process_log_message"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eae3ee8a",
      "metadata": {},
      "source": [
        "## Agent-as-a-Judge (Added by us)\n",
        "\n",
        "We added this evaluation layer using MLflow's `make_judge`. It evaluates the agent's trace using MCP tools to inspect execution details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cb1f5260",
      "metadata": {},
      "outputs": [],
      "source": [
        "log_monitor_judge = make_judge(\n",
        "    name=\"log_monitor_evaluator\",\n",
        "    instructions=(\n",
        "        \"Evaluate the log monitor agent's performance in {{ trace }}.\\n\\n\"\n",
        "        \"Check for:\\n\"\n",
        "        \"1. Classification Accuracy: Was the log correctly classified as error/warning/normal?\\n\"\n",
        "        \"2. Diagnosis Quality: Was the root cause analysis accurate and helpful?\\n\"\n",
        "        \"3. Severity Assessment: Was the severity (high/low) appropriate?\\n\"\n",
        "        \"4. Action Routing: Was the correct action taken (Slack for high, GitHub for low)?\\n\\n\"\n",
        "        \"Rate as: 'good', 'acceptable', or 'poor'\"\n",
        "    ),\n",
        "    feedback_value_type=Literal[\"good\", \"acceptable\", \"poor\"],\n",
        "    model=JUDGE_MODEL,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "37ea3931",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_trace(trace):\n",
        "    \"\"\"Run Agent-as-a-Judge evaluation and log to MLflow.\"\"\"\n",
        "    feedback = log_monitor_judge(trace=trace)\n",
        "    \n",
        "    trace_id = trace.info.trace_id\n",
        "    mlflow.log_feedback(\n",
        "        trace_id=trace_id,\n",
        "        name=\"log_monitor_evaluation\",\n",
        "        value=feedback.value,\n",
        "        rationale=feedback.rationale,\n",
        "        source=AssessmentSource(\n",
        "            source_type=AssessmentSourceType.LLM_JUDGE,\n",
        "            source_id=f\"agent-as-a-judge/{JUDGE_MODEL}\",\n",
        "        ),\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nEvaluation: {feedback.value}\")\n",
        "    print(f\"Rationale: {feedback.rationale}\")\n",
        "    return feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4801c4d9",
      "metadata": {},
      "source": [
        "## Sample Log Messages\n",
        "\n",
        "Real-world examples from common libraries. These logs benefit from the agent's MCP tools (DeepWiki, Context7) to look up documentation for accurate diagnosis.\n",
        "\n",
        "Categories:\n",
        "- **Kubernetes** - RBAC, resource not found, conflicts\n",
        "- **Redis** - Connection, watch, timeout errors\n",
        "- **Kafka** - Metadata, partition, producer errors\n",
        "- **SQLAlchemy** - Connection, integrity, pool errors\n",
        "- **LangChain** - Parser, tool call errors\n",
        "- **AWS Boto3** - Access denied, throttling\n",
        "- **Warnings** - Memory, certificate expiration\n",
        "- **Info** - Normal operational logs (no action needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7b6893e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample log messages - real-world examples that benefit from MCP tool research\n",
        "EXAMPLES = [\n",
        "    # === KUBERNETES PYTHON CLIENT ERRORS ===\n",
        "    \"ERROR: kubernetes.client.rest.ApiException: (403) Forbidden: pods is forbidden: User 'system:serviceaccount:default:myapp' cannot list resource 'pods' in API group '' in namespace 'production'\",\n",
        "    \"ERROR: kubernetes.client.rest.ApiException: (404) Not Found: deployments.apps 'nginx-deployment' not found in namespace 'staging'\",\n",
        "    \"ERROR: kubernetes.client.rest.ApiException: (409) Conflict: Operation cannot be fulfilled on configmaps 'app-config': the object has been modified; please apply your changes to the latest version\",\n",
        "    \n",
        "    # === REDIS-PY ERRORS ===\n",
        "    \"ERROR: redis.exceptions.ConnectionError: Error 111 connecting to redis-master:6379. Connection refused.\",\n",
        "    \"ERROR: redis.exceptions.WatchError: Watched variable changed during transaction - key 'inventory:item:12345' was modified by another client\",\n",
        "    \"ERROR: redis.exceptions.TimeoutError: Timeout reading from redis-cluster:6379 after 30.0 seconds\",\n",
        "    \n",
        "    # === KAFKA ERRORS ===\n",
        "    \"ERROR: kafka.errors.KafkaTimeoutError: Failed to update metadata after 60.0 secs - broker may be unreachable\",\n",
        "    \"ERROR: kafka.errors.NotLeaderForPartitionError: This server is not the leader for topic-partition orders-events-3\",\n",
        "    \"ERROR: org.apache.kafka.common.errors.ProducerFencedException: Producer with transactionalId 'order-processor' has been fenced by a newer producer instance\",\n",
        "    \n",
        "    # === SQLALCHEMY / DATABASE ERRORS ===\n",
        "    \"ERROR: sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at 'db.example.com' (10.0.1.50), port 5432 failed: Connection timed out\",\n",
        "    \"ERROR: sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint 'users_email_key' - DETAIL: Key (email)=(user@example.com) already exists\",\n",
        "    \"ERROR: sqlalchemy.pool.exc.TimeoutError: QueuePool limit of size 5 overflow 10 reached, connection timed out, timeout 30.00\",\n",
        "    \n",
        "    # === LANGCHAIN ERRORS ===\n",
        "    \"ERROR: langchain_core.exceptions.OutputParserException: Failed to parse LLM output - expected JSON object but received malformed response\",\n",
        "    \"ERROR: langchain.schema.InvalidToolCall: Tool 'search_database' received invalid arguments: missing required parameter 'query'\",\n",
        "    \n",
        "    # === AWS BOTO3 ERRORS ===\n",
        "    \"ERROR: botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the GetObject operation: Access Denied for s3://my-bucket/private/data.json\",\n",
        "    \"ERROR: botocore.exceptions.ClientError: An error occurred (ThrottlingException) when calling the DescribeInstances operation: Rate exceeded\",\n",
        "    \n",
        "    # === HIGH SEVERITY WARNINGS ===\n",
        "    \"WARNING: Memory usage at 94% on pod ml-inference-worker-7b9c4 - OOMKilled likely imminent\",\n",
        "    \"WARNING: Certificate for *.api.example.com expires in 12 hours (NotAfter: 2024-01-15T23:59:59Z)\",\n",
        "    \n",
        "    # === NORMAL/INFO LOGS (no action expected) ===\n",
        "    \"INFO: Successfully connected to PostgreSQL database at db.example.com:5432\",\n",
        "    \"INFO: Kafka consumer group 'order-processors' rebalanced - now consuming from partitions [0, 1, 2]\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d593e6dd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: ERROR: kubernetes.client.rest.ApiException: (403) Forbidden: pods is forbidden: User 'system:serviceaccount:default:myapp' cannot list resource 'pods' in API group '' in namespace 'production'\n",
            "\n",
            "[LLM] Using Llama Stack at http://localhost:8321\n",
            "[LLM] Model: openai/gpt-4o\n",
            "[Classify] Classification: error (confidence: 0.95)\n",
            "[Classify] Indicators: ['ERROR', 'kubernetes.client.rest.ApiException', 'Forbidden']\n",
            "[Diagnose] Analyzing root cause...\n",
            "[LLM] Using Llama Stack at http://localhost:8321\n",
            "[LLM] Model: openai/gpt-4o\n",
            "[MCP] Connecting to research tools...\n",
            "[MCP]   - DeepWiki: https://mcp.deepwiki.com/mcp\n",
            "[MCP]   - Context7: https://mcp.context7.com/mcp\n",
            "[MCP] Available tools: ['read_wiki_structure', 'read_wiki_contents', 'ask_question', 'resolve-library-id', 'query-docs']\n",
            "[Diagnose] MCP research tools available\n",
            "[Diagnose] Diagnosis: 1. **What went wrong**: The error log indicates that the service account `system:serviceaccount:default:myapp` does not have permission to list the resource `pods` in the `production` namespace.\n",
            "\n",
            "2. **Likely root cause**: The service account is missing the necessary role or role binding that allows it to perform the `list` action on pods within the specified namespace. This could be due to misconfigured or missing Kubernetes Role or RoleBinding for the service account.\n",
            "\n",
            "3. **Potential impact**: Without the necessary permissions, the application or service running with this service account will not be able to list pods in the `production` namespace, potentially affecting its functionality or any operations relying on pod information.\n",
            "[LLM] Using Llama Stack at http://localhost:8321\n",
            "[LLM] Model: openai/gpt-4o\n",
            "[Severity] Assessment: high (confidence: 0.95)\n",
            "[Severity] Reasoning: The error log reveals a permissions issue preventing the service account from listing pods, which is likely critical for application functionality. Since this issue directly impacts operations reliant on pod information, it is considered HIGH severity, as it represents a service degradation or a potential security issue if key functionalities are disrupted in the production environment. Immediate action is warranted to restore normal operations and ensure the application runs without interruption.\n",
            "STUB: Would send Slack alert to SRE: High severity issue detected - 1. **What went wrong**: The error log indicates that the service account `system:serviceaccount:default:myapp` does not have permission to list the resource `pods` in the `production` namespace.\n",
            "\n",
            "2. **Likely root cause**: The service account is missing the necessary role or role binding that allows it to perform the `list` action on pods within the specified namespace. This could be due to misconfigured or missing Kubernetes Role or RoleBinding for the service account.\n",
            "\n",
            "3. **Potential impact**: Without the necessary permissions, the application or service running with this service account will not be able to list pods in the `production` namespace, potentially affecting its functionality or any operations relying on pod information.\n",
            "STUB: Severity: high\n",
            "STUB: Diagnosis: 1. **What went wrong**: The error log indicates that the service account `system:serviceaccount:default:myapp` does not have permission to list the resource `pods` in the `production` namespace.\n",
            "\n",
            "2. **Likely root cause**: The service account is missing the necessary role or role binding that allows it to perform the `list` action on pods within the specified namespace. This could be due to misconfigured or missing Kubernetes Role or RoleBinding for the service account.\n",
            "\n",
            "3. **Potential impact**: Without the necessary permissions, the application or service running with this service account will not be able to list pods in the `production` namespace, potentially affecting its functionality or any operations relying on pod information.\n",
            "Action taken: slack_alert\n",
            "\n",
            "Result: {'log_message': \"ERROR: kubernetes.client.rest.ApiException: (403) Forbidden: pods is forbidden: User 'system:serviceaccount:default:myapp' cannot list resource 'pods' in API group '' in namespace 'production'\", 'classification': 'error', 'diagnosis': '1. **What went wrong**: The error log indicates that the service account `system:serviceaccount:default:myapp` does not have permission to list the resource `pods` in the `production` namespace.\\n\\n2. **Likely root cause**: The service account is missing the necessary role or role binding that allows it to perform the `list` action on pods within the specified namespace. This could be due to misconfigured or missing Kubernetes Role or RoleBinding for the service account.\\n\\n3. **Potential impact**: Without the necessary permissions, the application or service running with this service account will not be able to list pods in the `production` namespace, potentially affecting its functionality or any operations relying on pod information.', 'severity': 'high', 'action_taken': 'slack_alert'}\n",
            "\n",
            "Evaluation: good\n",
            "Rationale: 1. **Classification Accuracy:** The log was correctly classified as an \"error\" based on the input log message indicating a 403 Forbidden error related to Kubernetes.\n",
            "\n",
            "2. **Diagnosis Quality:** The diagnosis provided accurately identifies the root cause of the error: missing necessary permissions for the service account to list pods in the specified namespace. The analysis is clear, detailed, and helps identify the misconfiguration or missing role/role binding.\n",
            "\n",
            "3. **Severity Assessment:** The severity was appropriately assessed as \"high\". Given the error's potential impact of preventing the service or application from accessing critical resources, this assessment is justified.\n",
            "\n",
            "4. **Action Routing:** The correct action was taken by routing the alert to Slack, appropriate for a high-severity error. This ensures prompt attention from the SRE team.\n",
            "\n",
            "Overall, the log monitor agent performed all tasks accurately and efficiently, leading to a 'good' rating.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Feedback(name='log_monitor_evaluator', source=AssessmentSource(source_type='LLM_JUDGE', source_id='openai:/gpt-4o'), trace_id='tr-a391faf96e2b09c55e3691880236a3dc', run_id=None, rationale='1. **Classification Accuracy:** The log was correctly classified as an \"error\" based on the input log message indicating a 403 Forbidden error related to Kubernetes.\\n\\n2. **Diagnosis Quality:** The diagnosis provided accurately identifies the root cause of the error: missing necessary permissions for the service account to list pods in the specified namespace. The analysis is clear, detailed, and helps identify the misconfiguration or missing role/role binding.\\n\\n3. **Severity Assessment:** The severity was appropriately assessed as \"high\". Given the error\\'s potential impact of preventing the service or application from accessing critical resources, this assessment is justified.\\n\\n4. **Action Routing:** The correct action was taken by routing the alert to Slack, appropriate for a high-severity error. This ensures prompt attention from the SRE team.\\n\\nOverall, the log monitor agent performed all tasks accurately and efficiently, leading to a \\'good\\' rating.', metadata={'mlflow.assessment.judgeCost': 0.022150000000000003}, span_id=None, create_time_ms=1769723988102, last_update_time_ms=1769723988102, assessment_id=None, error=None, expectation=None, feedback=FeedbackValue(value='good', error=None), overrides=None, valid=True)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Process a log message (pick any index from EXAMPLES)\n",
        "log_message = EXAMPLES[0]  # Kubernetes RBAC error\n",
        "print(f\"Processing: {log_message}\\n\")\n",
        "\n",
        "result = process_log_message(log_message)\n",
        "print(f\"\\nResult: {result}\")\n",
        "\n",
        "# Evaluate the trace\n",
        "trace_id = mlflow.get_last_active_trace_id()\n",
        "trace = mlflow.get_trace(trace_id)\n",
        "evaluate_trace(trace)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04c4248e",
      "metadata": {},
      "source": [
        "## View Traces in MLflow UI\n",
        "\n",
        "Start the MLflow UI to view traces and assessments:\n",
        "\n",
        "```bash\n",
        "mlflow ui --port 5001\n",
        "```\n",
        "\n",
        "Then open http://localhost:5001 in your browser.\n",
        "\n",
        "### How to Navigate\n",
        "\n",
        "1. **Select the Experiment** - Click on `log-monitor-agent` in the left sidebar\n",
        "2. **Go to Traces tab** - Click the \"Traces\" tab to see all agent executions\n",
        "3. **View Trace Details** - Click on any Trace ID to open the trace detail view\n",
        "   - You'll see the span hierarchy showing each step (classify → diagnose → assess severity → route)\n",
        "   - Click on individual spans to see inputs/outputs for each step\n",
        "4. **View Assessments** - In the trace detail view, look for the assessments side-panel on the right\n",
        "   - This shows the Agent-as-a-Judge evaluation results (rating + rationale)\n",
        "   - In MLflow 3.2+, you can also see assessment columns directly in the traces list\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
