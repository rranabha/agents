{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Monitor Agent with OpenTelemetry Tracing & Evaluation\n",
    "\n",
    "An event-driven agent that monitors server logs using LangGraph, with **OpenTelemetry** tracing exported to MLflow via OTLP.\n",
    "\n",
    "**Source:** The agent is from https://github.com/jwm4/agents/tree/001-log-monitor-agent/examples/log-monitor-agent\n",
    "\n",
    "**What we added:** OpenTelemetry tracing (OTLP export to MLflow) and Agent-as-a-Judge evaluation to demonstrate observability and automated evaluation of agent execution.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Llama Stack server running at `http://localhost:8321`\n",
    "- MLflow server running: `mlflow server --backend-store-uri sqlite:///mlflow.db --port 5001`\n",
    "- `OPENAI_API_KEY` in environment (for Agent-as-a-Judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nnarendr/Documents/Repos/agents/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from parent directory (agents_tracing-eval_mlflow/.env)\n",
    "env_path = os.path.join(os.path.dirname(os.getcwd()), \".env\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "import mlflow\n",
    "from mlflow.genai.judges import make_judge\n",
    "from typing import Literal\n",
    "\n",
    "from opentelemetry import trace as otel_trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking: http://127.0.0.1:5001\n"
     ]
    }
   ],
   "source": [
    "JUDGE_MODEL = \"openai:/gpt-4o\"\n",
    "\n",
    "MLFLOW_TRACKING_URI = os.environ.get(\"MLFLOW_TRACKING_URI\", \"http://127.0.0.1:5001\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "experiment = mlflow.set_experiment(\"log-monitor-agent\")\n",
    "print(f\"MLflow tracking: {MLFLOW_TRACKING_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenTelemetry Tracing Setup\n",
    "\n",
    "Initialize a `TracerProvider` with an OTLP HTTP exporter that sends traces to the MLflow server.\n",
    "\n",
    "**Important:** The `TracerProvider` must be set globally *before* importing the agent module, so that the sub-module tracers (`agent.py`, `llm.py`, `tools.py`) pick up this provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init OTel tracing → OTLP export to MLflow\n",
    "# Must be set BEFORE importing agent so sub-module tracers use this provider\n",
    "tracer_provider = TracerProvider()\n",
    "tracer_provider.add_span_processor(BatchSpanProcessor(OTLPSpanExporter(\n",
    "    endpoint=f\"{MLFLOW_TRACKING_URI.rstrip('/')}/v1/traces\",\n",
    "    headers={\"x-mlflow-experiment-id\": experiment.experiment_id},\n",
    ")))\n",
    "otel_trace.set_tracer_provider(tracer_provider)\n",
    "tracer = otel_trace.get_tracer(\"log-monitor-agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Agent\n",
    "\n",
    "The log monitor agent implements a LangGraph workflow:\n",
    "1. **Classify** - error/warning/normal\n",
    "2. **Diagnose** - root cause analysis (uses MCP tools for documentation lookup)\n",
    "3. **Assess Severity** - high/low\n",
    "4. **Route** - Slack alert (high) or GitHub ticket (low)\n",
    "\n",
    "The OTel version (`log_monitor_agent_otel/`) uses `tracer.start_as_current_span()` calls to capture execution traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import agent AFTER TracerProvider is set up\n",
    "from log_monitor_agent_otel.agent import process_log_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_log_monitor(log_message: str) -> tuple[dict, str]:\n",
    "    \"\"\"Process a log message with OTel tracing. Returns (result, trace_id).\"\"\"\n",
    "    with tracer.start_as_current_span(\"log_monitor_agent\") as root:\n",
    "        root.set_attribute(\"input.question\", log_message)\n",
    "        root.set_attribute(\"mlflow.spanInputs\", json.dumps({\"log_message\": log_message}))\n",
    "\n",
    "        result = process_log_message(log_message)\n",
    "\n",
    "        root.set_attribute(\"output.response\", json.dumps({\n",
    "            \"classification\": result.get(\"classification\", \"\"),\n",
    "            \"diagnosis\": result.get(\"diagnosis\", \"\")[:2000],\n",
    "            \"severity\": result.get(\"severity\", \"\"),\n",
    "            \"action_taken\": result.get(\"action_taken\", \"\"),\n",
    "        }))\n",
    "        root.set_attribute(\"mlflow.spanOutputs\", json.dumps({\n",
    "            \"classification\": result.get(\"classification\", \"\"),\n",
    "            \"severity\": result.get(\"severity\", \"\"),\n",
    "            \"action_taken\": result.get(\"action_taken\", \"\"),\n",
    "            \"diagnosis\": result.get(\"diagnosis\", \"\")[:2000],\n",
    "        }))\n",
    "\n",
    "        trace_id = format(root.get_span_context().trace_id, \"032x\")\n",
    "\n",
    "    return result, trace_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent-as-a-Judge\n",
    "\n",
    "Two evaluation judges using MLflow's `make_judge`:\n",
    "\n",
    "1. **log_monitor_evaluator** - General performance evaluation (classification, diagnosis, severity, routing)\n",
    "2. **log_actionability** - Custom DevOps rubric that checks if alerts are actionable:\n",
    "   - Identifies the failing service\n",
    "   - Suggests a recovery action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_monitor_judge = make_judge(\n",
    "    name=\"log_monitor_evaluator\",\n",
    "    instructions=(\n",
    "        \"Evaluate the log monitor agent's performance in {{ trace }}.\\n\\n\"\n",
    "        \"Check for:\\n\"\n",
    "        \"1. Classification Accuracy: Was the log correctly classified as error/warning/normal?\\n\"\n",
    "        \"2. Diagnosis Quality: Was the root cause analysis accurate and helpful?\\n\"\n",
    "        \"3. Severity Assessment: Was the severity (high/low) appropriate?\\n\"\n",
    "        \"4. Action Routing: Was the correct action taken (Slack for high, GitHub for low)?\\n\\n\"\n",
    "        \"Rate as: 'good', 'acceptable', or 'poor'\"\n",
    "    ),\n",
    "    feedback_value_type=Literal[\"good\", \"acceptable\", \"poor\"],\n",
    "    model=JUDGE_MODEL,\n",
    ")\n",
    "\n",
    "log_actionability = make_judge(\n",
    "    name=\"log_actionability\",\n",
    "    instructions=(\n",
    "        \"You are a DevOps Lead evaluating log alert summaries for actionability.\\n\\n\"\n",
    "        \"Evaluate the agent's response in {{ trace }} using this RUBRIC:\\n\\n\"\n",
    "        \"A response is ACTIONABLE if it meets BOTH criteria:\\n\"\n",
    "        \"1. **Identifies the failing service**: The response clearly states which service, \"\n",
    "        \"component, or system is failing (e.g., 'Redis connection', 'Kubernetes RBAC', 'PostgreSQL database')\\n\"\n",
    "        \"2. **Suggests a recovery action**: The response provides at least one concrete step \"\n",
    "        \"to resolve or mitigate the issue (e.g., 'restart the pod', 'check RBAC permissions', \"\n",
    "        \"'increase connection pool size')\\n\\n\"\n",
    "        \"Rate as:\\n\"\n",
    "        \"- 'actionable': Meets BOTH criteria - identifies failing service AND suggests recovery action\\n\"\n",
    "        \"- 'partially_actionable': Meets only ONE criterion - either identifies service OR suggests action, but not both\\n\"\n",
    "        \"- 'not_actionable': Meets NEITHER criterion - unclear what failed or how to fix it\\n\\n\"\n",
    "        \"In your rationale, explicitly state:\\n\"\n",
    "        \"1. What failing service was identified (or 'none' if unclear)\\n\"\n",
    "        \"2. What recovery action was suggested (or 'none' if missing)\\n\"\n",
    "        \"3. Why you assigned this rating based on the rubric\"\n",
    "    ),\n",
    "    feedback_value_type=Literal[\"actionable\", \"partially_actionable\", \"not_actionable\"],\n",
    "    model=JUDGE_MODEL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Log Messages\n",
    "\n",
    "Real-world examples from common libraries. These logs benefit from the agent's MCP tools (DeepWiki, Context7) to look up documentation for accurate diagnosis.\n",
    "\n",
    "Categories:\n",
    "- **Kubernetes** - RBAC, resource not found, conflicts\n",
    "- **Redis** - Connection, watch, timeout errors\n",
    "- **Kafka** - Metadata, partition, producer errors\n",
    "- **SQLAlchemy** - Connection, integrity, pool errors\n",
    "- **LangChain** - Parser, tool call errors\n",
    "- **AWS Boto3** - Access denied, throttling\n",
    "- **Warnings** - Memory, certificate expiration\n",
    "- **Info** - Normal operational logs (no action needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample log messages - real-world examples that benefit from MCP tool research\n",
    "EXAMPLES = [\n",
    "    # === KUBERNETES PYTHON CLIENT ERRORS ===\n",
    "    \"ERROR: kubernetes.client.rest.ApiException: (403) Forbidden: pods is forbidden: User 'system:serviceaccount:default:myapp' cannot list resource 'pods' in API group '' in namespace 'production'\",\n",
    "    \"ERROR: kubernetes.client.rest.ApiException: (404) Not Found: deployments.apps 'nginx-deployment' not found in namespace 'staging'\",\n",
    "    \"ERROR: kubernetes.client.rest.ApiException: (409) Conflict: Operation cannot be fulfilled on configmaps 'app-config': the object has been modified; please apply your changes to the latest version\",\n",
    "    \n",
    "    # === REDIS-PY ERRORS ===\n",
    "    \"ERROR: redis.exceptions.ConnectionError: Error 111 connecting to redis-master:6379. Connection refused.\",\n",
    "    \"ERROR: redis.exceptions.WatchError: Watched variable changed during transaction - key 'inventory:item:12345' was modified by another client\",\n",
    "    \"ERROR: redis.exceptions.TimeoutError: Timeout reading from redis-cluster:6379 after 30.0 seconds\",\n",
    "    \n",
    "    # === KAFKA ERRORS ===\n",
    "    \"ERROR: kafka.errors.KafkaTimeoutError: Failed to update metadata after 60.0 secs - broker may be unreachable\",\n",
    "    \"ERROR: kafka.errors.NotLeaderForPartitionError: This server is not the leader for topic-partition orders-events-3\",\n",
    "    \"ERROR: org.apache.kafka.common.errors.ProducerFencedException: Producer with transactionalId 'order-processor' has been fenced by a newer producer instance\",\n",
    "    \n",
    "    # === SQLALCHEMY / DATABASE ERRORS ===\n",
    "    \"ERROR: sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at 'db.example.com' (10.0.1.50), port 5432 failed: Connection timed out\",\n",
    "    \"ERROR: sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint 'users_email_key' - DETAIL: Key (email)=(user@example.com) already exists\",\n",
    "    \"ERROR: sqlalchemy.pool.exc.TimeoutError: QueuePool limit of size 5 overflow 10 reached, connection timed out, timeout 30.00\",\n",
    "    \n",
    "    # === LANGCHAIN ERRORS ===\n",
    "    \"ERROR: langchain_core.exceptions.OutputParserException: Failed to parse LLM output - expected JSON object but received malformed response\",\n",
    "    \"ERROR: langchain.schema.InvalidToolCall: Tool 'search_database' received invalid arguments: missing required parameter 'query'\",\n",
    "    \n",
    "    # === AWS BOTO3 ERRORS ===\n",
    "    \"ERROR: botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the GetObject operation: Access Denied for s3://my-bucket/private/data.json\",\n",
    "    \"ERROR: botocore.exceptions.ClientError: An error occurred (ThrottlingException) when calling the DescribeInstances operation: Rate exceeded\",\n",
    "    \n",
    "    # === HIGH SEVERITY WARNINGS ===\n",
    "    \"WARNING: Memory usage at 94% on pod ml-inference-worker-7b9c4 - OOMKilled likely imminent\",\n",
    "    \"WARNING: Certificate for *.api.example.com expires in 12 hours (NotAfter: 2024-01-15T23:59:59Z)\",\n",
    "    \n",
    "    # === NORMAL/INFO LOGS (no action expected) ===\n",
    "    \"INFO: Successfully connected to PostgreSQL database at db.example.com:5432\",\n",
    "    \"INFO: Kafka consumer group 'order-processors' rebalanced - now consuming from partitions [0, 1, 2]\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Agent & Evaluate\n",
    "\n",
    "1. Process a log message (OTel traces sent via OTLP)\n",
    "2. Flush traces to MLflow and wait for ingestion\n",
    "3. Load traces via `mlflow.search_traces()`\n",
    "4. Evaluate with both judges via `mlflow.genai.evaluate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ERROR: kubernetes.client.rest.ApiException: (403) Forbidden: pods is forbidden: User 'system:serviceaccount:default:myapp' cannot list resource 'pods' in API group '' in namespace 'production'\n",
      "\n",
      "[LLM] Using Llama Stack at http://localhost:8321\n",
      "[LLM] Model: openai/gpt-4o\n",
      "[Classify] Classification: error (confidence: 0.95)\n",
      "[Classify] Indicators: ['ERROR', 'ApiException', '403 Forbidden', 'cannot list resource']\n",
      "[Diagnose] Analyzing root cause...\n",
      "[LLM] Using Llama Stack at http://localhost:8321\n",
      "[LLM] Model: openai/gpt-4o\n",
      "[MCP] Connecting to research tools...\n",
      "[MCP]   - DeepWiki: https://mcp.deepwiki.com/mcp\n",
      "[MCP]   - Context7: https://mcp.context7.com/mcp\n",
      "[MCP] Available tools: ['read_wiki_structure', 'read_wiki_contents', 'ask_question', 'resolve-library-id', 'query-docs']\n",
      "[Diagnose] MCP research tools available\n",
      "[Diagnose] Diagnosis: The error message indicates a permissions issue: a Kubernetes service account, identified as 'system:serviceaccount:default:myapp', lacks the necessary permissions to list 'pods' in the 'production' namespace. The root cause is likely a missing or improperly configured RoleBinding or ClusterRoleBinding that grants this service account the required permissions to access the 'pods' resource. The impact is that the application or process running under this service account will be unable to perform actions related to listing pods, potentially disrupting monitoring, scaling, or logging operations that depend on this capability.\n",
      "[LLM] Using Llama Stack at http://localhost:8321\n",
      "[LLM] Model: openai/gpt-4o\n",
      "[Severity] Assessment: low (confidence: 0.85)\n",
      "[Severity] Reasoning: While the lack of permissions prevents the service account from listing pods, the error does not directly result in immediate service degradation, security breaches, or data loss. However, it could potentially disrupt operations that rely on this capability, such as monitoring or scaling. Therefore, although it might hinder operational efficiency, it does not necessitate immediate resolution at the expense of other priorities.\n",
      "STUB: Checking for existing GitHub issue: The error message indicates a permissions issue: a Kubernetes service account, identified as 'system:serviceaccount:default:myapp', lacks the necessary permissions to list 'pods' in the 'production' namespace. The root cause is likely a missing or improperly configured RoleBinding or ClusterRoleBinding that grants this service account the required permissions to access the 'pods' resource. The impact is that the application or process running under this service account will be unable to perform actions related to listing pods, potentially disrupting monitoring, scaling, or logging operations that depend on this capability.\n",
      "STUB: No existing issue found (stub always returns False)\n",
      "STUB: Would create GitHub issue: [Auto] ERROR: kubernetes.client.rest.ApiException: (403) ...\n",
      "STUB: Issue body preview: ## Log Message\n",
      "ERROR: kubernetes.client.rest.ApiException: (403) Forbidden: pods is forbidden: User ...\n",
      "Action taken: github_ticket\n",
      "\n",
      "Result: {'log_message': \"ERROR: kubernetes.client.rest.ApiException: (403) Forbidden: pods is forbidden: User 'system:serviceaccount:default:myapp' cannot list resource 'pods' in API group '' in namespace 'production'\", 'classification': 'error', 'diagnosis': \"The error message indicates a permissions issue: a Kubernetes service account, identified as 'system:serviceaccount:default:myapp', lacks the necessary permissions to list 'pods' in the 'production' namespace. The root cause is likely a missing or improperly configured RoleBinding or ClusterRoleBinding that grants this service account the required permissions to access the 'pods' resource. The impact is that the application or process running under this service account will be unable to perform actions related to listing pods, potentially disrupting monitoring, scaling, or logging operations that depend on this capability.\", 'severity': 'low', 'action_taken': 'github_ticket'}\n",
      "Trace ID: 6abba83b5ae4be7f284f342c07aff2ae\n",
      "\n",
      "Flushing traces to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/09 14:01:50 INFO mlflow.models.evaluation.utils.trace: Auto tracing is temporarily enabled during the model evaluation for computing some metrics and debugging. To disable tracing, call `mlflow.autolog(disable=True)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading traces from MLflow...\n",
      "Found 1 trace(s) matching this run.\n",
      "\n",
      "=== Running agent-as-a-judge evaluation ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:33, Remaining: 00:00] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <title>Evaluation output</title>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "\n",
       "        .header {\n",
       "            a.button {\n",
       "                padding: 4px 8px;\n",
       "                line-height: 20px;\n",
       "                box-shadow: none;\n",
       "                height: 20px;\n",
       "                display: inline-flex;\n",
       "                align-items: center;\n",
       "                justify-content: center;\n",
       "                vertical-align: middle;\n",
       "                background-color: rgb(34, 114, 180);\n",
       "                color: rgb(255, 255, 255);\n",
       "                text-decoration: none;\n",
       "                animation-duration: 0s;\n",
       "                transition: none 0s ease 0s;\n",
       "                position: relative;\n",
       "                white-space: nowrap;\n",
       "                text-align: center;\n",
       "                border: 1px solid rgb(192, 205, 216);\n",
       "                cursor: pointer;\n",
       "                user-select: none;\n",
       "                touch-action: manipulation;\n",
       "                border-radius: 4px;\n",
       "                gap: 6px;\n",
       "            }\n",
       "\n",
       "            a.button:hover {\n",
       "                background-color: rgb(14, 83, 139) !important;\n",
       "                border-color: transparent !important;\n",
       "                color: rgb(255, 255, 255) !important;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .warnings-section {\n",
       "            margin-top: 8px;\n",
       "\n",
       "            ul {\n",
       "                list-style-type: none;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .instructions-section {\n",
       "            margin-top: 16px;\n",
       "            font-size: 14px;\n",
       "\n",
       "            ul {\n",
       "                margin-top: 0;\n",
       "                margin-bottom: 0;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        code {\n",
       "            font-family: monospace;\n",
       "        }\n",
       "\n",
       "        .note {\n",
       "            color: #666;\n",
       "        }\n",
       "\n",
       "        a {\n",
       "            color: #2272B4;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "\n",
       "        a:hover {\n",
       "            color: #005580;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "    <div class=\"header\">\n",
       "        <a href=\"http://127.0.0.1:5001/#/experiments/2/evaluation-runs?selectedRunUuid=5bc586813e7d4e618381eb10923f0714\" class=\"button\">\n",
       "            View evaluation results in MLflow\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1em\" height=\"1em\" fill=\"none\" viewBox=\"0 0 16 16\" aria-hidden=\"true\" focusable=\"false\" class=\"\">\n",
       "                <path fill=\"currentColor\" d=\"M10 1h5v5h-1.5V3.56L8.53 8.53 7.47 7.47l4.97-4.97H10z\"></path>\n",
       "                <path fill=\"currentColor\" d=\"M1 2.75A.75.75 0 0 1 1.75 2H8v1.5H2.5v10h10V8H14v6.25a.75.75 0 0 1-.75.75H1.75a.75.75 0 0 1-.75-.75z\"></path>\n",
       "            </svg>\n",
       "        </a>\n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation results ---\n",
      "\n",
      "eval_results:\n",
      "  log_actionability/value: actionable\n",
      "  log_monitor_evaluator/value: good\n"
     ]
    }
   ],
   "source": [
    "# Process a log message (pick any index from EXAMPLES)\n",
    "log_message = EXAMPLES[0]  # Kubernetes RBAC error\n",
    "print(f\"Processing: {log_message}\\n\")\n",
    "\n",
    "result, trace_id = run_log_monitor(log_message)\n",
    "print(f\"\\nResult: {result}\")\n",
    "print(f\"Trace ID: {trace_id}\")\n",
    "\n",
    "# Flush OTel traces to MLflow\n",
    "print(\"\\nFlushing traces to MLflow...\")\n",
    "tracer_provider.force_flush()\n",
    "time.sleep(2)\n",
    "\n",
    "# Load traces from MLflow and evaluate with both judges\n",
    "print(\"Loading traces from MLflow...\")\n",
    "traces_df = mlflow.search_traces(locations=[experiment.experiment_id])\n",
    "\n",
    "# Keep only traces produced in this run\n",
    "for col in (\"request_id\", \"client_request_id\", \"trace_id\"):\n",
    "    if not traces_df.empty and col in traces_df.columns:\n",
    "        match_ids = [trace_id] if col != \"trace_id\" else [f\"tr-{trace_id}\"]\n",
    "        filtered = traces_df[traces_df[col].isin(match_ids)]\n",
    "        if not filtered.empty:\n",
    "            traces_df = filtered\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(traces_df)} trace(s) matching this run.\\n\")\n",
    "\n",
    "if traces_df.empty:\n",
    "    print(\n",
    "        \"ERROR: No traces found. Make sure MLflow server is running:\\n\"\n",
    "        \"  mlflow server --backend-store-uri sqlite:///mlflow.db --port 5001\\n\"\n",
    "    )\n",
    "else:\n",
    "    print(\"=== Running agent-as-a-judge evaluation ===\\n\")\n",
    "    results = mlflow.genai.evaluate(\n",
    "        data=traces_df,\n",
    "        scorers=[log_monitor_judge, log_actionability],\n",
    "    )\n",
    "    print(\"--- Evaluation results ---\")\n",
    "    for name, table in results.tables.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        for _, row in table.iterrows():\n",
    "            for col in table.columns:\n",
    "                if any(j in str(col) for j in (\"log_monitor_evaluator\", \"log_actionability\")):\n",
    "                    print(f\"  {col}: {row[col]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Traces in MLflow UI\n",
    "\n",
    "The MLflow server should already be running (required for OTLP export). Open it in your browser:\n",
    "\n",
    "```bash\n",
    "# If not already running:\n",
    "mlflow server --backend-store-uri sqlite:///mlflow.db --port 5001\n",
    "```\n",
    "\n",
    "Then open http://localhost:5001 in your browser.\n",
    "\n",
    "### How to Navigate\n",
    "\n",
    "1. **Select the Experiment** - Click on `log-monitor-agent` in the left sidebar\n",
    "2. **Go to Traces tab** - Click the \"Traces\" tab to see all agent executions\n",
    "3. **View Trace Details** - Click on any Trace ID to open the trace detail view\n",
    "   - You'll see the span hierarchy showing each step (classify → diagnose → assess severity → route)\n",
    "   - Click on individual spans to see inputs/outputs for each step\n",
    "4. **View Assessments** - In the trace detail view, look for the assessments side-panel on the right\n",
    "   - This shows the Agent-as-a-Judge evaluation results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
