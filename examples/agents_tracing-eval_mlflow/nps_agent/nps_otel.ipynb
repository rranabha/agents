{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPS Agent with OpenTelemetry Tracing & Agent-as-a-Judge\n",
    "\n",
    "Query the National Parks Service using LlamaStack + MCP, with **OpenTelemetry** tracing exported to MLflow via OTLP, and automated evaluation.\n",
    "\n",
    "**Prerequisites:**\n",
    "- LlamaStack server on `localhost:8321`\n",
    "- NPS MCP server on `localhost:3005`\n",
    "- MLflow server running: `mlflow server --backend-store-uri sqlite:///mlflow.db --port 5001`\n",
    "- `OPENAI_API_KEY` in environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nnarendr/Documents/Repos/agents/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from parent directory (agents_tracing-eval_mlflow/.env)\n",
    "env_path = os.path.join(os.path.dirname(os.getcwd()), \".env\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "import mlflow\n",
    "from mlflow.genai.judges import make_judge\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from typing import Literal\n",
    "\n",
    "from opentelemetry import trace as otel_trace\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "LLAMA_STACK_URL = \"http://localhost:8321/\"\n",
    "NPS_MCP_URL = \"http://localhost:3005/sse/\"\n",
    "MODEL_ID = \"openai/gpt-4o\"\n",
    "JUDGE_MODEL = \"openai:/gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking: http://127.0.0.1:5001\n"
     ]
    }
   ],
   "source": [
    "MLFLOW_TRACKING_URI = os.environ.get(\"MLFLOW_TRACKING_URI\", \"http://127.0.0.1:5001\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "experiment = mlflow.set_experiment(\"nps-agent\")\n",
    "print(f\"MLflow tracking: {MLFLOW_TRACKING_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenTelemetry Tracing Setup\n",
    "\n",
    "Initialize a `TracerProvider` with an OTLP HTTP exporter that sends traces to the MLflow server.\n",
    "\n",
    "- **Endpoint**: `{MLFLOW_TRACKING_URI}/v1/traces`\n",
    "- **Header**: `x-mlflow-experiment-id` tells MLflow which experiment the traces belong to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init OTel tracing → OTLP export to MLflow\n",
    "tracer_provider = TracerProvider()\n",
    "tracer_provider.add_span_processor(BatchSpanProcessor(OTLPSpanExporter(\n",
    "    endpoint=f\"{MLFLOW_TRACKING_URI.rstrip('/')}/v1/traces\",\n",
    "    headers={\"x-mlflow-experiment-id\": experiment.experiment_id},\n",
    ")))\n",
    "otel_trace.set_tracer_provider(tracer_provider)\n",
    "tracer = otel_trace.get_tracer(\"nps-agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Function\n",
    "\n",
    "Queries NPS via LlamaStack with MCP tools attached. Uses OTel `tracer.start_as_current_span()` to create spans with input/output attributes that the judge can inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_nps(prompt: str, model: str = MODEL_ID) -> tuple[str, str]:\n",
    "    \"\"\"Query the National Parks Service agent. Returns (response_text, trace_id).\"\"\"\n",
    "    client = LlamaStackClient(base_url=LLAMA_STACK_URL)\n",
    "\n",
    "    with tracer.start_as_current_span(\"query_nps\") as root:\n",
    "        root.set_attribute(\"input.question\", prompt)\n",
    "        root.set_attribute(\"mlflow.spanInputs\", json.dumps({\"prompt\": prompt}))\n",
    "\n",
    "        with tracer.start_as_current_span(\"mcp_tool_call\") as span:\n",
    "            span.set_attribute(\"model\", model)\n",
    "            span.set_attribute(\"input.prompt\", prompt)\n",
    "            response = client.responses.create(\n",
    "                model=model,\n",
    "                input=prompt,\n",
    "                tools=[{\"type\": \"mcp\", \"server_url\": NPS_MCP_URL, \"server_label\": \"NPS tools\"}],\n",
    "            )\n",
    "            span.set_attribute(\"response.id\", response.id)\n",
    "            span.set_attribute(\"response.status\", response.status)\n",
    "\n",
    "            # Record tool calls from the response so the judge can see them\n",
    "            for i, output in enumerate(response.output):\n",
    "                if hasattr(output, \"type\"):\n",
    "                    span.set_attribute(f\"output.{i}.type\", output.type)\n",
    "                if hasattr(output, \"name\"):\n",
    "                    span.set_attribute(f\"output.{i}.name\", output.name)\n",
    "                if hasattr(output, \"arguments\") and output.arguments:\n",
    "                    span.set_attribute(f\"output.{i}.arguments\", str(output.arguments)[:1000])\n",
    "\n",
    "        # Extract text response\n",
    "        result = \"\"\n",
    "        for output in response.output:\n",
    "            if output.type in (\"text\", \"message\") and hasattr(output, \"content\") and output.content:\n",
    "                result = output.content[0].text\n",
    "                break\n",
    "\n",
    "        root.set_attribute(\"output.response\", result[:4000])\n",
    "        root.set_attribute(\"mlflow.spanOutputs\", json.dumps({\"response\": result[:4000]}))\n",
    "        trace_id = format(root.get_span_context().trace_id, \"032x\")\n",
    "\n",
    "    return result, trace_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent-as-a-Judge\n",
    "\n",
    "An Agent that evaluates the agent's trace after execution. Instead of just looking at inputs/outputs, it uses tools to inspect the full execution:\n",
    "- What spans were created\n",
    "- What tools were called\n",
    "- How long each step took\n",
    "\n",
    "The `{{ trace }}` in the instructions tells MLflow to give the judge these inspection tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent-as-a-Judge scorer\n",
    "nps_judge = make_judge(\n",
    "    name=\"nps_agent_evaluator\",\n",
    "    instructions=(\n",
    "        \"Evaluate the NPS agent's performance in {{ trace }}.\\n\\n\"\n",
    "        \"Check for:\\n\"\n",
    "        \"1. Response Quality: Did the agent correctly identify parks and provide accurate information?\\n\"\n",
    "        \"2. Tool Usage: Were the correct NPS MCP tools used (search_parks, get_park_events, etc.)?\\n\"\n",
    "        \"3. Completeness: Did the agent answer all parts of the user's question?\\n\\n\"\n",
    "        \"Rate as: 'good', 'acceptable', or 'poor'\"\n",
    "    ),\n",
    "    feedback_value_type=Literal[\"good\", \"acceptable\", \"poor\"],\n",
    "    model=JUDGE_MODEL,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Agent & Evaluate\n",
    "\n",
    "1. Send a query to the NPS agent (OTel traces sent via OTLP)\n",
    "2. Flush traces to MLflow and wait for ingestion\n",
    "3. Load traces via `mlflow.search_traces()`\n",
    "4. Evaluate with `mlflow.genai.evaluate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Here are some of the national parks in Rhode Island and their upcoming events:\n",
      "\n",
      "### Blackstone River Valley National Historical Park\n",
      "- **Description**: The Blackstone River was pivotal to America's entry into the Age of Industry, starting with Samuel Slater's cotton spinning mill in Pawtucket, RI. It's a place where you can learn about how this industrial revolution changed the landscape and lives in the Blackstone Valley and beyond.\n",
      "- **Website**: [More Info](https://www.nps.gov/blrv/index.htm)\n",
      "\n",
      "**Upcoming Events**:\n",
      "1. **Revolutionary War Pension Files Transcription Event**\n",
      "   - **Date**: February 10 and February 20, 2026\n",
      "   - **Venue**: Carpenter Museum and Upton Community Center in Massachusetts\n",
      "   - **Description**: Participate in transcribing Revolutionary War Pension Files. It's free and open to all.\n",
      "   \n",
      "2. **Old Slater Mill Tour**\n",
      "   - **Description**: A guided tour of Slater Mill, the start of the American Industrial Revolution. The tour is 30 minutes long and begins at various times during the day.\n",
      "   - **Location**: 67 Roosevelt Avenue, Pawtucket, RI 02860\n",
      "\n",
      "3. **Take Me Fishing**\n",
      "   - **Dates**: Sundays in June, July, and August\n",
      "   - **Location**: Kelly House Barn, Blackstone River State Park\n",
      "   - **Description**: Learn to fish and have family fun with all materials provided.\n",
      "\n",
      "4. **Hike the Blackstone Gorge with the Blackstone Watershed Collaborative**\n",
      "   - **Location**: Blackstone River Valley\n",
      "   - **Description**: Witness the geologic features and scenic views on this 1.2-mile hike.\n",
      "\n",
      "### Roger Williams National Memorial\n",
      "- **Description**: The memorial acknowledges Roger Williams' legacy, highlighting his advocacy for religious freedom and liberty.\n",
      "- **Website**: [More Info](https://www.nps.gov/rowi/index.htm)\n",
      "\n",
      "**Upcoming Events**:\n",
      "1. **Visitor Center Open**\n",
      "   - **Description**: Discover the life and legacy of Roger Williams via exhibits, films, and a bookstore.\n",
      "\n",
      "2. **Lunchtime Arts in the Park**\n",
      "   - **Dates**: June 11th, July 9th, August 13th, September 10th at noon\n",
      "   - **Description**: Free songwriting workshops with Mark Cutler. All skill levels welcome.\n",
      "\n",
      "### Touro Synagogue National Historic Site\n",
      "- **Description**: A historic Jewish synagogue celebrated for its design and historical significance in America. It still serves as a center of worship and attracts over 30,000 visitors annually.\n",
      "- **Website**: [More Info](https://www.nps.gov/tosy/index.htm)\n",
      "\n",
      "**Upcoming Events**: Currently, no upcoming events are planned.\n",
      "\n",
      "### Washington-Rochambeau Revolutionary Route National Historic Trail\n",
      "- **Description**: A trail marking the route of the allied American and French forces in the Revolutionary War.\n",
      "- **Website**: [More Info](https://www.nps.gov/waro/index.htm)\n",
      "\n",
      "**Upcoming Events**: No upcoming events are scheduled.\n",
      "Trace ID: cf3711918c3693f96a3afd34aabf338e\n",
      "\n",
      "Flushing traces to MLflow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/09 13:53:04 INFO mlflow.models.evaluation.utils.trace: Auto tracing is temporarily enabled during the model evaluation for computing some metrics and debugging. To disable tracing, call `mlflow.autolog(disable=True)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading traces from MLflow...\n",
      "Found 1 trace(s) matching this run.\n",
      "\n",
      "=== Running agent-as-a-judge evaluation ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/1 [Elapsed: 00:00, Remaining: ?] \u001b[92m13:53:04 - LiteLLM:INFO\u001b[0m: utils.py:3879 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "\u001b[92m13:53:05 - LiteLLM:INFO\u001b[0m: utils.py:1629 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:53:05 - LiteLLM:INFO\u001b[0m: utils.py:3879 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "\u001b[92m13:53:06 - LiteLLM:INFO\u001b[0m: utils.py:1629 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:53:06 - LiteLLM:INFO\u001b[0m: utils.py:3879 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "\u001b[92m13:53:07 - LiteLLM:INFO\u001b[0m: utils.py:1629 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:53:07 - LiteLLM:INFO\u001b[0m: utils.py:3879 - \n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o; provider = openai\n",
      "\u001b[92m13:53:11 - LiteLLM:INFO\u001b[0m: utils.py:1629 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:07, Remaining: 00:00] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <title>Evaluation output</title>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "\n",
       "        .header {\n",
       "            a.button {\n",
       "                padding: 4px 8px;\n",
       "                line-height: 20px;\n",
       "                box-shadow: none;\n",
       "                height: 20px;\n",
       "                display: inline-flex;\n",
       "                align-items: center;\n",
       "                justify-content: center;\n",
       "                vertical-align: middle;\n",
       "                background-color: rgb(34, 114, 180);\n",
       "                color: rgb(255, 255, 255);\n",
       "                text-decoration: none;\n",
       "                animation-duration: 0s;\n",
       "                transition: none 0s ease 0s;\n",
       "                position: relative;\n",
       "                white-space: nowrap;\n",
       "                text-align: center;\n",
       "                border: 1px solid rgb(192, 205, 216);\n",
       "                cursor: pointer;\n",
       "                user-select: none;\n",
       "                touch-action: manipulation;\n",
       "                border-radius: 4px;\n",
       "                gap: 6px;\n",
       "            }\n",
       "\n",
       "            a.button:hover {\n",
       "                background-color: rgb(14, 83, 139) !important;\n",
       "                border-color: transparent !important;\n",
       "                color: rgb(255, 255, 255) !important;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .warnings-section {\n",
       "            margin-top: 8px;\n",
       "\n",
       "            ul {\n",
       "                list-style-type: none;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .instructions-section {\n",
       "            margin-top: 16px;\n",
       "            font-size: 14px;\n",
       "\n",
       "            ul {\n",
       "                margin-top: 0;\n",
       "                margin-bottom: 0;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        code {\n",
       "            font-family: monospace;\n",
       "        }\n",
       "\n",
       "        .note {\n",
       "            color: #666;\n",
       "        }\n",
       "\n",
       "        a {\n",
       "            color: #2272B4;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "\n",
       "        a:hover {\n",
       "            color: #005580;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "    <div class=\"header\">\n",
       "        <a href=\"http://127.0.0.1:5001/#/experiments/1/evaluation-runs?selectedRunUuid=436044b80db346dab33d3b6dabe5c7e5\" class=\"button\">\n",
       "            View evaluation results in MLflow\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1em\" height=\"1em\" fill=\"none\" viewBox=\"0 0 16 16\" aria-hidden=\"true\" focusable=\"false\" class=\"\">\n",
       "                <path fill=\"currentColor\" d=\"M10 1h5v5h-1.5V3.56L8.53 8.53 7.47 7.47l4.97-4.97H10z\"></path>\n",
       "                <path fill=\"currentColor\" d=\"M1 2.75A.75.75 0 0 1 1.75 2H8v1.5H2.5v10h10V8H14v6.25a.75.75 0 0 1-.75.75H1.75a.75.75 0 0 1-.75-.75z\"></path>\n",
       "            </svg>\n",
       "        </a>\n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation results ---\n",
      "\n",
      "eval_results:\n",
      "  nps_agent_evaluator/value: good\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me about some parks in Rhode Island, and let me know if there are any upcoming events at them.\"\n",
    "\n",
    "result, trace_id = query_nps(prompt)\n",
    "print(f\"Response:\\n{result}\")\n",
    "print(f\"Trace ID: {trace_id}\")\n",
    "\n",
    "# Flush OTel traces to MLflow\n",
    "print(\"\\nFlushing traces to MLflow...\")\n",
    "tracer_provider.force_flush()\n",
    "time.sleep(2)\n",
    "\n",
    "# Load traces from MLflow and evaluate with agent-as-a-judge\n",
    "print(\"Loading traces from MLflow...\")\n",
    "traces_df = mlflow.search_traces(locations=[experiment.experiment_id])\n",
    "\n",
    "# Keep only traces produced in this run\n",
    "for col in (\"request_id\", \"client_request_id\", \"trace_id\"):\n",
    "    if not traces_df.empty and col in traces_df.columns:\n",
    "        match_ids = [trace_id] if col != \"trace_id\" else [f\"tr-{trace_id}\"]\n",
    "        filtered = traces_df[traces_df[col].isin(match_ids)]\n",
    "        if not filtered.empty:\n",
    "            traces_df = filtered\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(traces_df)} trace(s) matching this run.\\n\")\n",
    "\n",
    "if traces_df.empty:\n",
    "    print(\n",
    "        \"ERROR: No traces found. Make sure MLflow server is running:\\n\"\n",
    "        \"  mlflow server --backend-store-uri sqlite:///mlflow.db --port 5001\\n\"\n",
    "    )\n",
    "else:\n",
    "    print(\"=== Running agent-as-a-judge evaluation ===\\n\")\n",
    "    results = mlflow.genai.evaluate(\n",
    "        data=traces_df,\n",
    "        scorers=[nps_judge],\n",
    "    )\n",
    "    print(\"--- Evaluation results ---\")\n",
    "    for name, table in results.tables.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        for _, row in table.iterrows():\n",
    "            for col in table.columns:\n",
    "                if \"nps_agent_evaluator\" in str(col):\n",
    "                    print(f\"  {col}: {row[col]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Traces in MLflow UI\n",
    "\n",
    "The MLflow server should already be running (required for OTLP export). Open it in your browser:\n",
    "\n",
    "```bash\n",
    "# If not already running:\n",
    "mlflow server --backend-store-uri sqlite:///mlflow.db --port 5001\n",
    "```\n",
    "\n",
    "Then open http://localhost:5001 in your browser.\n",
    "\n",
    "### How to Navigate\n",
    "\n",
    "1. **Select the Experiment** - Click on `nps-agent` in the left sidebar\n",
    "2. **Go to Traces tab** - Click the \"Traces\" tab to see all agent executions\n",
    "3. **View Trace Details** - Click on any Trace ID to open the trace detail view\n",
    "   - You'll see the span hierarchy showing the agent execution (query_nps → mcp_tool_call)\n",
    "   - Click on individual spans to see inputs/outputs for each step\n",
    "4. **View Assessments** - In the trace detail view, look for the assessments side-panel on the right\n",
    "   - This shows the Agent-as-a-Judge evaluation results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
